import gradio as gr
import os
import tempfile
from openai import OpenAI
import tempfile
import anyio


# Set an environment variable for key
# os.environ['OPENAI_API_KEY'] = os.environ.get('OPENAI_API_KEY')

# client = OpenAI() # add api_key

from scipy.io import wavfile
from scipy.io.wavfile import write

from speechbrain.pretrained import SpectralMaskEnhancement

enhance_model = SpectralMaskEnhancement.from_hparams(
    source="speechbrain/metricgan-plus-voicebank",
    savedir="pretrained_models/metricgan-plus-voicebank",
)

knn_vc = torch.hub.load('bshall/knn-vc', 'knn_vc', prematched=True,
                        trust_repo=True, pretrained=True, device='cpu')

language_dict = tts_order_voice


async def text_to_speech_edge(text, language_code):
    voice = language_dict[language_code]
    communicate = edge_tts.Communicate(text, voice)
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp_file:
        tmp_path = tmp_file.name

    await communicate.save(tmp_path)

    return "è¯­éŸ³åˆæˆå®Œæˆï¼š{}".format(text), tmp_path


def voice_change(audio_in, audio_ref):
    samplerate1, data1 = wavfile.read(audio_in)
    samplerate2, data2 = wavfile.read(audio_ref)
    write("./audio_in.wav", samplerate1, data1)
    write("./audio_ref.wav", samplerate2, data2)

    query_seq = knn_vc.get_features("./audio_in.wav")
    matching_set = knn_vc.get_matching_set(["./audio_ref.wav"])
    out_wav = knn_vc.match(query_seq, matching_set, topk=4)
    torchaudio.save('output.wav', out_wav[None], 16000)
    noisy = enhance_model.load_audio(
        'output.wav'
    ).unsqueeze(0)
    enhanced = enhance_model.enhance_batch(noisy, lengths=torch.tensor([1.]))
    torchaudio.save('enhanced.wav', enhanced.cpu(), 16000)
    return 'enhanced.wav'


def tts(text, model, voice, api_key):
    if len(text) > 300:
        raise gr.Error('æ‚¨è¾“å…¥çš„æ–‡æœ¬å­—ç¬¦å¤šäº300ä¸ªï¼Œè¯·ç¼©çŸ­æ‚¨çš„æ–‡æœ¬')
    if api_key == '':
        raise gr.Error('Please enter your OpenAI API Key')
    else:
        try:
            client = OpenAI(api_key=api_key)

            response = client.audio.speech.create(
                model=model,  # "tts-1","tts-1-hd"
                voice=voice,  # 'alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer'
                input=text,
            )

        except Exception as error:
            # Handle any exception that occurs
            raise gr.Error(
                "An error occurred while generating speech. Please check your API key and try again.")
            print(str(error))

    # Create a temp file to save the audio
    with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as temp_file:
        temp_file.write(response.content)

    # Get the file path of the temp file
    temp_file_path = temp_file.name

    return temp_file_path


app = gr.Blocks()

with app:
    gr.Markdown("# <center>ğŸŒŸ - TTS-Core </center>")
    with gr.Tab("ğŸ¤— Local-Model TTS"):
        with gr.Row(variant='panel'):
            api_key = gr.Textbox(
                type='password', label='OpenAI API Key', placeholder='è¯·åœ¨æ­¤å¡«å†™æ‚¨çš„OpenAI API Key')
            model = gr.Dropdown(choices=[
                                'tts-1', 'tts-1-hd'], label='è¯·é€‰æ‹©æ¨¡å‹ï¼ˆtts-1æ¨ç†æ›´å¿«ï¼Œtts-1-hdéŸ³è´¨æ›´å¥½ï¼‰', value='tts-1')
            voice = gr.Dropdown(choices=[
                                'alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer'], label='è¯·é€‰æ‹©ä¸€ä¸ªè¯´è¯äºº', value='alloy')
        with gr.Row():
            with gr.Column():
                inp_text = gr.Textbox(
                    label="è¯·å¡«å†™æ‚¨æƒ³ç”Ÿæˆçš„æ–‡æœ¬ï¼ˆä¸­è‹±æ–‡çš†å¯ï¼‰", placeholder="æƒ³è¯´å´è¿˜æ²¡è¯´çš„ è¿˜å¾ˆå¤š æ”’ç€æ˜¯å› ä¸ºæƒ³å†™æˆæ­Œ", lines=5)
                btn_text = gr.Button("ä¸€é”®å¼€å¯çœŸå®æ‹Ÿå£°å§", variant="primary")

            with gr.Column():
                inp1 = gr.Audio(type="filepath",
                                label="OpenAI TTSçœŸå®æ‹Ÿå£°", interactive=False)
                inp2 = gr.Audio(type="filepath",
                                label="è¯·ä¸Šä¼ AIå˜å£°çš„å‚ç…§éŸ³é¢‘ï¼ˆå†³å®šå˜å£°åçš„è¯­éŸ³éŸ³è‰²ï¼‰")
                btn1 = gr.Button("ä¸€é”®å¼€å¯AIå˜å£°å§", variant="primary")
            with gr.Column():
                out1 = gr.Audio(type="filepath", label="AIå˜å£°åçš„ä¸“å±éŸ³é¢‘")
            btn_text.click(tts, [inp_text, model, voice, api_key], inp1)
            btn1.click(voice_change, [inp1, inp2], out1)
    with gr.Tab("âš¡ Edge TTS"):
        with gr.Row():
            input_text = gr.Textbox(
                lines=5, placeholder="æƒ³è¯´å´è¿˜æ²¡è¯´çš„ è¿˜å¾ˆå¤š æ”’ç€æ˜¯å› ä¸ºæƒ³å†™æˆæ­Œ", label="è¯·å¡«å†™æ‚¨æƒ³ç”Ÿæˆçš„æ–‡æœ¬ï¼ˆä¸­è‹±æ–‡çš†å¯ï¼‰")
            default_language = list(language_dict.keys())[15]
            language = gr.Dropdown(choices=list(
                language_dict.keys()), value=default_language, label="è¯·é€‰æ‹©æ–‡æœ¬å¯¹åº”çš„è¯­è¨€")
            btn_edge = gr.Button("ä¸€é”®å¼€å¯çœŸå®æ‹Ÿå£°å§", variant="primary")
            output_text = gr.Textbox(label="è¾“å‡ºæ–‡æœ¬", visible=False)
            output_audio = gr.Audio(type="filepath", label="Edge TTSçœŸå®æ‹Ÿå£°")

        with gr.Row():
            inp_vc = gr.Audio(
                type="filepath", label="è¯·ä¸Šä¼ AIå˜å£°çš„å‚ç…§éŸ³é¢‘ï¼ˆå†³å®šå˜å£°åçš„è¯­éŸ³éŸ³è‰²ï¼‰")
            btn_vc = gr.Button("ä¸€é”®å¼€å¯AIå˜å£°å§", variant="primary")
            out_vc = gr.Audio(type="filepath", label="AIå˜å£°åçš„ä¸“å±éŸ³é¢‘")

        btn_edge.click(text_to_speech_edge, [input_text, language], [
                       output_text, output_audio])
        btn_vc.click(voice_change, [output_audio, inp_vc], out_vc)

    gr.Markdown(
        "### <center>æ³¨æ„â—ï¼šè¯·ä¸è¦ç”Ÿæˆä¼šå¯¹ä¸ªäººä»¥åŠç»„ç»‡é€ æˆä¾µå®³çš„å†…å®¹ï¼Œæ­¤ç¨‹åºä»…ä¾›ç§‘ç ”ã€å­¦ä¹ åŠä¸ªäººå¨±ä¹ä½¿ç”¨ã€‚Get your OpenAI API Key [here](https://platform.openai.com/api-keys).</center>")
    gr.HTML('''
        <div class="footer">
                    <p>ğŸŒŠğŸï¸ğŸ¶ - æ±Ÿæ°´ä¸œæµæ€¥ï¼Œæ»”æ»”æ— å°½å£°ã€‚ æ˜Â·é¡¾ç’˜
                    </p>
        </div>
    ''')

app.launch(show_error=True)
